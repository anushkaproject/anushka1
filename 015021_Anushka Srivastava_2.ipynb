{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This notebooks analyses the personal details of the patients and builds a machine learning model which can be used to predict the medical cost of the patients given his personal details using pyspark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up pyspark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "# Setup pyspark sc\n",
    "conf = SparkConf().setAll([('spark.executor.memory', '2g')])\n",
    "sc =SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For this project \"Attachment_1635667446.csv\" file has been used which has been copied to hadoop before loading into pyspark using below shown command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command to copy data file into HADOOP"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hadoop fs -put Attachment_1635667446.csv /data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The dataset contains below columns:\n",
    "•age: age of primary beneficiary\n",
    "•sex: insurance contractor gender, female, male\n",
    "•bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n",
    "•children: Number of children covered by health insurance / Number of dependents\n",
    "•smoker: Smoking\n",
    "•region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
    "•charges: Individual medical costs billed by health insurance\n",
    "In this project, using the rest other columns we are supposed to predict \"charges\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data read and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "data = sqlContext.read.format('com.databricks.spark.csv').\\\n",
    "        options(header='true', inferschema='true').\\\n",
    "        load('Attachment_1635667446.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- children: integer (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- charges: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# columns schema of the data\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Patients count by various categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   sex|count|\n",
      "+------+-----+\n",
      "|female|  662|\n",
      "|  male|  676|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count by sex\n",
    "data.groupBy('sex').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|children|count|\n",
      "+--------+-----+\n",
      "|       1|  324|\n",
      "|       3|  157|\n",
      "|       5|   18|\n",
      "|       4|   25|\n",
      "|       2|  240|\n",
      "|       0|  574|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count by dependent childrens\n",
    "data.groupBy('children').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|smoker|count|\n",
      "+------+-----+\n",
      "|    no| 1064|\n",
      "|   yes|  274|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count by smoker type\n",
    "data.groupBy('smoker').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|   region|count|\n",
      "+---------+-----+\n",
      "|northwest|  325|\n",
      "|southeast|  364|\n",
      "|northeast|  324|\n",
      "|southwest|  325|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count by region\n",
    "data.groupBy('region').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This section involves indexing the string data type values to integer values and feature engineering the data to prepare cleaned dataset for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+---------+------------+-------------+---------+------------+---------+--------------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|sex_index|smoker_index|charges_index|bmi_index|region_index|age_index|children_index|\n",
      "+---+------+------+--------+------+---------+-----------+---------+------------+-------------+---------+------------+---------+--------------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|      1.0|         1.0|        340.0|    412.0|         2.0|      1.0|           0.0|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|      0.0|         0.0|        358.0|    283.0|         0.0|      0.0|           1.0|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|      0.0|         0.0|        891.0|     32.0|         0.0|     17.0|           3.0|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|      0.0|         0.0|        500.0|    130.0|         1.0|     30.0|           0.0|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|      0.0|         0.0|        783.0|      2.0|         1.0|     29.0|           0.0|\n",
      "+---+------+------+--------+------+---------+-----------+---------+------------+-------------+---------+------------+---------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "# String Indexing\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(data) for column in list(set(data.columns)-set(['Provider_Id, Provider_Zip_Code, Total_Discharges, Average_Covered_Charges, Average_Total_Payments, Average_Medicare_Payments'])) ]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df_r = pipeline.fit(data).transform(data)\n",
    "df_r.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|            features|    charges|\n",
      "+--------------------+-----------+\n",
      "|[19.0,0.0,27.9,2....|  16884.924|\n",
      "|[18.0,1.0,33.77,0...|  1725.5523|\n",
      "|[28.0,3.0,33.0,0....|   4449.462|\n",
      "|[33.0,0.0,22.705,...|21984.47061|\n",
      "|[32.0,0.0,28.88,1...|  3866.8552|\n",
      "|[31.0,0.0,25.74,0...|  3756.6216|\n",
      "|[46.0,1.0,33.44,0...|  8240.5896|\n",
      "|[37.0,3.0,27.74,1...|  7281.5056|\n",
      "|[37.0,2.0,29.83,3...|  6406.4107|\n",
      "|[60.0,0.0,25.84,1...|28923.13692|\n",
      "+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Feature assembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"age\",\"children\",\"bmi\",\"region_index\", \"smoker_index\", \"sex_index\"], outputCol=\"features\")\n",
    "output = assembler.transform(df_r)\n",
    "output.select('features', 'charges').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The transformed data has been split into train and test data sets in the ratio of 70:30 as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split for modelling\n",
    "splits = output.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Linear Regression model has been trained on the feature vectors data on the train data set as to predict the charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Model training\n",
    "lr = LinearRegression(maxIter=5, regParam=0.0, labelCol='charges', solver=\"normal\")\n",
    "mymodel = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5969.818040\n",
      "r2: 0.759403\n"
     ]
    }
   ],
   "source": [
    "# Model training summary\n",
    "trainingSummary = mymodel.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Above model summary with RMSE of ~5970 and R2 of 0.75 values shows that the model has low error value and has captured 75% variance in the data to understand the pattern of charges variable. Hence the model is the best fit model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+----------+---------+------------+-------------+---------+------------+---------+--------------+--------------------+------------------+\n",
      "|age|   sex|   bmi|children|smoker|   region|   charges|sex_index|smoker_index|charges_index|bmi_index|region_index|age_index|children_index|            features|        prediction|\n",
      "+---+------+------+--------+------+---------+----------+---------+------------+-------------+---------+------------+---------+--------------+--------------------+------------------+\n",
      "| 18|female| 21.66|       0|   yes|northeast|14283.4594|      1.0|         1.0|        267.0|    128.0|         3.0|      0.0|           0.0|[18.0,0.0,21.66,3...| 24453.53104470655|\n",
      "| 18|female|28.215|       0|    no|northeast|2200.83085|      1.0|         0.0|        501.0|     89.0|         3.0|      0.0|           0.0|[18.0,0.0,28.215,...|2319.2883886873988|\n",
      "| 18|female|30.115|       0|    no|northeast|21344.8467|      1.0|         0.0|        479.0|     29.0|         3.0|      0.0|           0.0|[18.0,0.0,30.115,...|2953.8751698358483|\n",
      "| 18|female| 31.13|       0|    no|southeast| 1621.8827|      1.0|         0.0|        312.0|     99.0|         0.0|      0.0|           0.0|[18.0,0.0,31.13,0...|2318.9906875620327|\n",
      "| 18|female| 36.85|       0|    no|southeast| 1629.8335|      1.0|         0.0|        318.0|     65.0|         0.0|      0.0|           0.0|[18.0,0.0,36.85,0...| 4229.430891861581|\n",
      "+---+------+------+--------+------+---------+----------+---------+------------+-------------+---------+------------+---------+--------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions on the test set using trained model\n",
    "predictions = mymodel.transform(test_df)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy Measurement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79.18602899510151, 6270.427188013057)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"charges\")\n",
    "rmse = evaluator.evaluate(predictions,{evaluator.metricName:\"rmse\" })\n",
    "\n",
    "import numpy as np\n",
    "np.sqrt(rmse), rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.724998\n"
     ]
    }
   ],
   "source": [
    "print(\"R Squared (R2) on test data = %g\" % evaluator.evaluate(predictions,{evaluator.metricName:\"r2\" }))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The accuracy measurement of the trained Linear Regression Model has been done on the test data set predictions which is of ~6270 RMSE and ~0.73 R2 values indicating the model is able to predict the charges from the details of the patient on the test data set, hence the trained model is best fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From this excercise we can conclude that a regression model has been built and performance of the same has been validated in pyspark to predict the medical charges of patients given his details. R2 and RMSE have been used as the accuracy measurement parameters. The trained model and the test set predictions have nearly low RMSE and R2 values hence best fit model has been created.\n",
    "\n",
    "This excercise also helps to understand the end to end stages in regression modelling using pyspark in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
